{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4ZaYQzX9T9M92+RUJC+uN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnabende/ahumain-big-data-course-development/blob/main/ngram_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkZGyU3l6Ng8"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample documents\n",
        "\n",
        "documents = [\n",
        "    \"Web mining is useful\",\n",
        "    \"Usage mining applications\",\n",
        "    \"Web structure mining studies the Web hyperlink structures\"\n",
        "]"
      ],
      "metadata": {
        "id": "yWfrTVyh6W3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate 3-grams from a word\n",
        "\n",
        "def generate_ngrams(word, n=3):\n",
        "  return [word[i:i+n] for i in range(len(word) - n + 1)]"
      ],
      "metadata": {
        "id": "A_Cxs_vY6rZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize documents and build n-gram index\n",
        "\n",
        "def tokenize(text):\n",
        "  return text.lower().split()\n",
        "\n",
        "def build_ngram_index(docs, n=3):\n",
        "  index = defaultdict(lambda: defaultdict(list))\n",
        "  for doc_id, doc in enumerate(docs):\n",
        "    tokens = tokenize(doc)\n",
        "    for token in tokens:\n",
        "      ngrams = generate_ngrams(token, n)\n",
        "      for ngram in ngrams:\n",
        "        index[ngram][doc_id].append(token)\n",
        "  return index"
      ],
      "metadata": {
        "id": "g1fbVK_a64U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the ngram index\n",
        "\n",
        "ngram_index = build_ngram_index(documents)"
      ],
      "metadata": {
        "id": "oPdBw1Sg7dzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the ngram index\n",
        "\n",
        "def print_ngram_index(index):\n",
        "  for ngram, postings in index.items():\n",
        "    print(f\"N-gram: {ngram}\")\n",
        "    for doc_id, tokens in postings.items():\n",
        "      print(f\"  Document ID: {doc_id}, Tokens: {tokens}\")\n",
        "\n",
        "print_ngram_index(ngram_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WKPYYe47lkU",
        "outputId": "b99aa0fc-6d5a-4a68-e296-96b03e978feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-gram: web\n",
            "  Document ID: 0, Tokens: ['web']\n",
            "  Document ID: 2, Tokens: ['web', 'web']\n",
            "N-gram: min\n",
            "  Document ID: 0, Tokens: ['mining']\n",
            "  Document ID: 1, Tokens: ['mining']\n",
            "  Document ID: 2, Tokens: ['mining']\n",
            "N-gram: ini\n",
            "  Document ID: 0, Tokens: ['mining']\n",
            "  Document ID: 1, Tokens: ['mining']\n",
            "  Document ID: 2, Tokens: ['mining']\n",
            "N-gram: nin\n",
            "  Document ID: 0, Tokens: ['mining']\n",
            "  Document ID: 1, Tokens: ['mining']\n",
            "  Document ID: 2, Tokens: ['mining']\n",
            "N-gram: ing\n",
            "  Document ID: 0, Tokens: ['mining']\n",
            "  Document ID: 1, Tokens: ['mining']\n",
            "  Document ID: 2, Tokens: ['mining']\n",
            "N-gram: use\n",
            "  Document ID: 0, Tokens: ['useful']\n",
            "N-gram: sef\n",
            "  Document ID: 0, Tokens: ['useful']\n",
            "N-gram: efu\n",
            "  Document ID: 0, Tokens: ['useful']\n",
            "N-gram: ful\n",
            "  Document ID: 0, Tokens: ['useful']\n",
            "N-gram: usa\n",
            "  Document ID: 1, Tokens: ['usage']\n",
            "N-gram: sag\n",
            "  Document ID: 1, Tokens: ['usage']\n",
            "N-gram: age\n",
            "  Document ID: 1, Tokens: ['usage']\n",
            "N-gram: app\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: ppl\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: pli\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: lic\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: ica\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: cat\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: ati\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: tio\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: ion\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: ons\n",
            "  Document ID: 1, Tokens: ['applications']\n",
            "N-gram: str\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: tru\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: ruc\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: uct\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: ctu\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: tur\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: ure\n",
            "  Document ID: 2, Tokens: ['structure', 'structures']\n",
            "N-gram: stu\n",
            "  Document ID: 2, Tokens: ['studies']\n",
            "N-gram: tud\n",
            "  Document ID: 2, Tokens: ['studies']\n",
            "N-gram: udi\n",
            "  Document ID: 2, Tokens: ['studies']\n",
            "N-gram: die\n",
            "  Document ID: 2, Tokens: ['studies']\n",
            "N-gram: ies\n",
            "  Document ID: 2, Tokens: ['studies']\n",
            "N-gram: the\n",
            "  Document ID: 2, Tokens: ['the']\n",
            "N-gram: hyp\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: ype\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: per\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: erl\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: rli\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: lin\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: ink\n",
            "  Document ID: 2, Tokens: ['hyperlink']\n",
            "N-gram: res\n",
            "  Document ID: 2, Tokens: ['structures']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to search for documents containing ngrams of the query\n",
        "\n",
        "def ngram_search(query, index, docs, n=3):\n",
        "  query_ngrams = generate_ngrams(query, n)\n",
        "  matching_docs = defaultdict(int)\n",
        "\n",
        "  for ngram in query_ngrams:\n",
        "    if ngram in index:\n",
        "      for doc_id in index[ngram]:\n",
        "        matching_docs[doc_id] += 1\n",
        "\n",
        "  # Rank documents by the number of matching n-grams\n",
        "  ranked_docs = sorted(matching_docs.items(), key=lambda x: x[1], reverse=True)\n",
        "  return [doc_id for doc_id, _ in ranked_docs]\n",
        "\n"
      ],
      "metadata": {
        "id": "AKTl4Vi17dX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example ngram search\n",
        "\n",
        "query = \"usge\"\n",
        "result_docs = ngram_search(query, ngram_index, documents)\n",
        "print(f\"Query '{query}' matched documents: {result_docs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UWKxLv16dQz",
        "outputId": "d2d8989a-dfc4-4ed4-cbcf-144266a13989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 'usge' matched documents: []\n"
          ]
        }
      ]
    }
  ]
}